{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7101f5d",
   "metadata": {},
   "source": [
    "## BlackCoffer Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36d2350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL_ID of URL 1 is: blackassign0001\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0001.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 2 is: blackassign0002\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0002.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 3 is: blackassign0003\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0003.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 4 is: blackassign0004\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0004.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 5 is: blackassign0005\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0005.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 6 is: blackassign0006\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0006.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 7 is: blackassign0007\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0007.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 8 is: blackassign0008\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0008.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 9 is: blackassign0009\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0009.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 10 is: blackassign0010\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0010.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 11 is: blackassign0011\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0011.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 12 is: blackassign0012\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0012.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 13 is: blackassign0013\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0013.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 14 is: blackassign0014\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0014.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 15 is: blackassign0015\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0015.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 16 is: blackassign0016\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0016.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 17 is: blackassign0017\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0017.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 18 is: blackassign0018\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0018.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 19 is: blackassign0019\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0019.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 20 is: blackassign0020\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0020.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 21 is: blackassign0021\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0021.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 22 is: blackassign0022\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0022.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 23 is: blackassign0023\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0023.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 24 is: blackassign0024\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0024.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 25 is: blackassign0025\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0025.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 26 is: blackassign0026\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0026.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 27 is: blackassign0027\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0027.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 28 is: blackassign0028\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0028.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 29 is: blackassign0029\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0029.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 30 is: blackassign0030\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0030.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 31 is: blackassign0031\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0031.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 32 is: blackassign0032\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0032.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 33 is: blackassign0033\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0033.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 34 is: blackassign0034\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0034.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL_ID of URL 35 is: blackassign0035\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0035.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 36 is: blackassign0036\n",
      "URL_ID: blackassign0036 , Error: 'NoneType' object has no attribute 'text'\n",
      "Sorry, but the page you are looking for doesn't exist.\n",
      "Error occurred while processing URL https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "URL_ID of URL 37 is: blackassign0037\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0037.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 38 is: blackassign0038\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0038.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 39 is: blackassign0039\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0039.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 40 is: blackassign0040\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0040.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 41 is: blackassign0041\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0041.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 42 is: blackassign0042\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0042.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 43 is: blackassign0043\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0043.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 44 is: blackassign0044\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0044.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 45 is: blackassign0045\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0045.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 46 is: blackassign0046\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0046.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 47 is: blackassign0047\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0047.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 48 is: blackassign0048\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0048.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 49 is: blackassign0049\n",
      "URL_ID: blackassign0049 , Error: 'NoneType' object has no attribute 'text'\n",
      "Sorry, but the page you are looking for doesn't exist.\n",
      "Error occurred while processing URL https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "URL_ID of URL 50 is: blackassign0050\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0050.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 51 is: blackassign0051\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0051.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 52 is: blackassign0052\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0052.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 53 is: blackassign0053\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0053.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 54 is: blackassign0054\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0054.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 55 is: blackassign0055\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0055.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 56 is: blackassign0056\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0056.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 57 is: blackassign0057\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0057.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 58 is: blackassign0058\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0058.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 59 is: blackassign0059\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0059.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 60 is: blackassign0060\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0060.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 61 is: blackassign0061\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0061.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 62 is: blackassign0062\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0062.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 63 is: blackassign0063\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0063.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 64 is: blackassign0064\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0064.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 65 is: blackassign0065\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0065.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 66 is: blackassign0066\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0066.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 67 is: blackassign0067\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0067.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL_ID of URL 68 is: blackassign0068\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0068.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 69 is: blackassign0069\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0069.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 70 is: blackassign0070\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0070.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 71 is: blackassign0071\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0071.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 72 is: blackassign0072\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0072.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 73 is: blackassign0073\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0073.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 74 is: blackassign0074\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0074.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 75 is: blackassign0075\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0075.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 76 is: blackassign0076\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0076.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 77 is: blackassign0077\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0077.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 78 is: blackassign0078\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0078.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 79 is: blackassign0079\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0079.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 80 is: blackassign0080\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0080.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 81 is: blackassign0081\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0081.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 82 is: blackassign0082\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0082.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 83 is: blackassign0083\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0083.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 84 is: blackassign0084\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0084.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 85 is: blackassign0085\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0085.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 86 is: blackassign0086\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0086.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 87 is: blackassign0087\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0087.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 88 is: blackassign0088\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0088.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 89 is: blackassign0089\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0089.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 90 is: blackassign0090\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0090.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 91 is: blackassign0091\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0091.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 92 is: blackassign0092\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0092.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 93 is: blackassign0093\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0093.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 94 is: blackassign0094\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0094.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 95 is: blackassign0095\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0095.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 96 is: blackassign0096\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0096.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 97 is: blackassign0097\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0097.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 98 is: blackassign0098\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0098.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 99 is: blackassign0099\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0099.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "URL_ID of URL 100 is: blackassign0100\n",
      "\n",
      "Article Text of the URL saved in file: Articles_Txt_Files\\blackassign0100.txt\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Read the DataFrame outside the loop\n",
    "df = pd.read_excel(\"input.xlsx\")\n",
    "\n",
    "# Create a folder to store text files\n",
    "folder_name = \"Articles_Txt_Files\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Loop\n",
    "for i in range(len(df[\"URL\"])):\n",
    "    try:\n",
    "        url = df[\"URL\"][i]\n",
    "        url_id = df[\"URL_ID\"][i]\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        print(f\"URL_ID of URL {i+1} is:\", df[\"URL_ID\"][i])\n",
    "\n",
    "        Article_Text = \"\"\n",
    "        h1 = soup.find(\"body\").find(\"h1\")\n",
    "        title = h1.text.strip()\n",
    "        if h1:\n",
    "            Article_Text += f\"Title: {title}\\n\\n\"\n",
    "\n",
    "        paragraphs = soup.find(\"article\").find_all(\"p\")\n",
    "    #     print(\"Text of the URL :\")\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            cleaned_text = paragraph.text.strip()\n",
    "            Article_Text += cleaned_text + \"\\n\"\n",
    "    #         print(cleaned_text)\n",
    "\n",
    "        # Save the article text in file\n",
    "        file_path = os.path.join(folder_name, f\"{url_id}.txt\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(Article_Text)\n",
    "\n",
    "        print(f\"\\nArticle Text of the URL saved in file: {file_path}\\n\")\n",
    "        print(\"-----------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"URL_ID:\", url_id, \", Error:\", e)\n",
    "        print(\"Sorry, but the page you are looking for doesn't exist.\")\n",
    "        print(f\"Error occurred while processing URL {url}\\n\")\n",
    "        print(\"-------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52ca4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text_dir = \"Articles_Txt_Files\"\n",
    "stopwords_dir = \"StopWords\"\n",
    "sentiment_dir = \"MasterDictionary\"\n",
    "\n",
    "# Load all stop words from the stopwords directory and store in the set variable\n",
    "stop_words = set()\n",
    "for file_name in os.listdir(stopwords_dir):\n",
    "    with open(os.path.join(stopwords_dir, file_name), 'r', encoding='ISO-8859-1') as f:\n",
    "        stop_words.update(set(f.read().splitlines()))\n",
    "\n",
    "# Load all text files from the directory and store in a list (docs)\n",
    "docs = []\n",
    "for file_name in os.listdir(text_dir):\n",
    "    file_path = os.path.join(text_dir, file_name)\n",
    "    if os.path.isdir(file_path):\n",
    "        continue  # Skip directories\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:  # Use UTF-8 encoding\n",
    "        text = f.read()\n",
    "        # Tokenize the given text file\n",
    "        words = word_tokenize(text)\n",
    "        # Remove the stop words from the tokens\n",
    "        filtered_text = [word for word in words if word.lower() not in stop_words]\n",
    "        # Add each filtered tokens of each file into a list\n",
    "        docs.append(filtered_text)\n",
    "\n",
    "# Store positive and negative words from the directory\n",
    "pos = set()\n",
    "neg = set()\n",
    "\n",
    "for file_name in os.listdir(sentiment_dir):\n",
    "    with open(os.path.join(sentiment_dir, file_name), 'r', encoding='ISO-8859-1') as f:\n",
    "        if file_name == 'positive-words.txt':\n",
    "            pos.update(f.read().splitlines())\n",
    "        else:\n",
    "            neg.update(f.read().splitlines())\n",
    "\n",
    "# Now collect the positive and negative words from each file\n",
    "# Calculate the scores from the positive and negative words \n",
    "positive_words = []\n",
    "negative_words = []\n",
    "positive_score = []\n",
    "negative_score = []\n",
    "polarity_score = []\n",
    "subjectivity_score = []\n",
    "\n",
    "# Iterate through the list of docs\n",
    "for doc in docs:\n",
    "    positive_words.append([word for word in doc if word.lower() in pos])\n",
    "    negative_words.append([word for word in doc if word.lower() in neg])\n",
    "    positive_score.append(len(positive_words[-1]))\n",
    "    negative_score.append(len(negative_words[-1]))\n",
    "    polarity_score.append((positive_score[-1] - negative_score[-1]) / ((positive_score[-1] + negative_score[-1]) + 0.000001))\n",
    "    subjectivity_score.append((positive_score[-1] + negative_score[-1]) / (len(doc) + 0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8341d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Download the stopwords corpus if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "avg_sentence_length = []\n",
    "Percentage_of_Complex_words = []\n",
    "Fog_Index = []\n",
    "complex_word_count = []\n",
    "avg_syllable_word_count = []\n",
    "\n",
    "# Avoid variable name conflict by renaming\n",
    "stop_words_set = set(stopwords.words('english'))\n",
    "\n",
    "def measure(file):\n",
    "    if file.endswith('.ipynb_checkpoints'):\n",
    "        return None, None, None, None, None  # Skip the file\n",
    "    with open(os.path.join(text_dir, file), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    # remove punctuations \n",
    "    text = re.sub(r'[^\\w\\s.]', '', text)\n",
    "    # split the given text file into sentences\n",
    "    sentences = text.split('.')\n",
    "    # total number of sentences in a file\n",
    "    num_sentences = len(sentences)\n",
    "    # total words in the file\n",
    "    words = [word for word in text.split() if word.lower() not in stop_words_set]\n",
    "    num_words = len(words)\n",
    "\n",
    "    # complex words having syllable count is greater than 2\n",
    "    # Complex words are words in the text that contain more than two syllables.\n",
    "    complex_words = [word for word in words if count_syllables(word) > 2]\n",
    "\n",
    "    # Syllable Count Per Word\n",
    "    total_syllables = sum(count_syllables(word) for word in words)\n",
    "\n",
    "    avg_sentence_len = num_words / num_sentences\n",
    "    avg_syllable_word_count = total_syllables / len(words)\n",
    "    Percent_Complex_words = len(complex_words) / num_words\n",
    "    Fog_Index = 0.4 * (avg_sentence_len + Percent_Complex_words)\n",
    "\n",
    "    return avg_sentence_len, Percent_Complex_words, Fog_Index, len(complex_words), avg_syllable_word_count\n",
    "\n",
    "# Function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    if word.endswith('es'):\n",
    "        word = word[:-2]\n",
    "    elif word.endswith('ed'):\n",
    "        word = word[:-2]\n",
    "    vowels = 'aeiou'\n",
    "    return sum(1 for letter in word if letter.lower() in vowels)\n",
    "\n",
    "# iterate through each file or doc\n",
    "for file in os.listdir(text_dir):\n",
    "    x, y, z, a, b = measure(file)\n",
    "    if x is not None:\n",
    "        avg_sentence_length.append(x)\n",
    "        Percentage_of_Complex_words.append(y)\n",
    "        Fog_Index.append(z)\n",
    "        complex_word_count.append(a)\n",
    "        avg_syllable_word_count.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de89f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords corpus if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "word_count = []\n",
    "average_word_length = []\n",
    "pp_count = []\n",
    "\n",
    "# Avoid variable name conflict by renaming\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "def cleaned_words(file):\n",
    "    with open(os.path.join(text_dir, file), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        words = [word for word in text.split() if word.lower() not in stopwords_set]\n",
    "        length = sum(len(word) for word in words)\n",
    "        average_word_length = length / len(words)\n",
    "    return len(words), average_word_length\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    with open(os.path.join(text_dir, file), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n",
    "        count = 0\n",
    "        for pronoun in personal_pronouns:\n",
    "            count += len(re.findall(r\"\\b\" + pronoun + r\"\\b\", text)) # \\b is used to match word boundaries\n",
    "    return count\n",
    "\n",
    "for file in os.listdir(text_dir):\n",
    "    if file.endswith('.ipynb_checkpoints'):\n",
    "        continue  # Skip directories\n",
    "    x, y = cleaned_words(file)\n",
    "    word_count.append(x)\n",
    "    average_word_length.append(y)\n",
    "    pp_count.append(count_personal_pronouns(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2ce13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_excel('Output Data Structure.xlsx')\n",
    "\n",
    "# URLs with IDs 36 and 49 do not exist (404 error), so we are going to drop these rows from the table\n",
    "output_df.drop([36, 49], axis=0, inplace=True)\n",
    "\n",
    "# These are the required parameters \n",
    "variables = [positive_score,\n",
    "            negative_score,\n",
    "            polarity_score,\n",
    "            subjectivity_score,\n",
    "            avg_sentence_length,\n",
    "            Percentage_of_Complex_words,\n",
    "            Fog_Index,\n",
    "            avg_sentence_length,\n",
    "            complex_word_count,\n",
    "            word_count,\n",
    "            avg_syllable_word_count,\n",
    "            pp_count,\n",
    "            average_word_length]\n",
    "\n",
    "# Write the values to the dataframe\n",
    "for i, var in enumerate(variables):\n",
    "    output_df.iloc[:, i+2] = var\n",
    "\n",
    "# Now save the dataframe to disk\n",
    "output_df.to_csv('Output_Data_BlackCoffer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9758135",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad39cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. In this Assignment while scrapping BlackCoffer URL from input.xlsx file, 2 URL of URL_ID = blackassign0036, blackassign0049\n",
    "#    is not in the service as giving 404 error due to which the data is extracted from this two particualar file\n",
    "\n",
    "# 2. While remaining all the URL's data (Title and text of the page) has been extracted Sucessfully in Folder named as :  \n",
    "#    'Articles_Txt_Files'.\n",
    "\n",
    "# 3. All the required parameters : positive_score, negative_score, polarity_score, subjectivity_score, avg_sentence_length,\n",
    "#    Percentage_of_Complex_words, Fog_Index, avg_sentence_length, complex_word_count, word_count, avg_syllable_word_count,\n",
    "#    pp_count, average_word_length as been founded Sucessfully and has been stored in new file named as : \n",
    "#    'Output_Data_BlackCoffer.csv'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
